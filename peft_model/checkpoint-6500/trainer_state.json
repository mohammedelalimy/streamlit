{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.835951134380454,
  "eval_steps": 500,
  "global_step": 6500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.22,
      "learning_rate": 1.8545666084933103e-05,
      "loss": 1.4175,
      "step": 500
    },
    {
      "epoch": 0.44,
      "learning_rate": 1.70913321698662e-05,
      "loss": 1.4087,
      "step": 1000
    },
    {
      "epoch": 0.65,
      "learning_rate": 1.5636998254799302e-05,
      "loss": 1.3808,
      "step": 1500
    },
    {
      "epoch": 0.87,
      "learning_rate": 1.4182664339732403e-05,
      "loss": 1.3703,
      "step": 2000
    },
    {
      "epoch": 1.0,
      "eval_bleu": 44.7837,
      "eval_gen_len": 15.2685,
      "eval_loss": 1.237654447555542,
      "eval_runtime": 110.3495,
      "eval_samples_per_second": 18.124,
      "eval_steps_per_second": 0.761,
      "step": 2292
    },
    {
      "epoch": 1.09,
      "learning_rate": 1.2728330424665504e-05,
      "loss": 1.3555,
      "step": 2500
    },
    {
      "epoch": 1.31,
      "learning_rate": 1.1273996509598604e-05,
      "loss": 1.3705,
      "step": 3000
    },
    {
      "epoch": 1.53,
      "learning_rate": 9.819662594531705e-06,
      "loss": 1.3614,
      "step": 3500
    },
    {
      "epoch": 1.75,
      "learning_rate": 8.365328679464807e-06,
      "loss": 1.3821,
      "step": 4000
    },
    {
      "epoch": 1.96,
      "learning_rate": 6.91390343222804e-06,
      "loss": 1.3613,
      "step": 4500
    },
    {
      "epoch": 2.0,
      "eval_bleu": 44.8235,
      "eval_gen_len": 15.243,
      "eval_loss": 1.2311534881591797,
      "eval_runtime": 111.343,
      "eval_samples_per_second": 17.963,
      "eval_steps_per_second": 0.754,
      "step": 4584
    },
    {
      "epoch": 2.18,
      "learning_rate": 5.4624781849912745e-06,
      "loss": 1.3791,
      "step": 5000
    },
    {
      "epoch": 2.4,
      "learning_rate": 4.008144269924375e-06,
      "loss": 1.3473,
      "step": 5500
    },
    {
      "epoch": 2.62,
      "learning_rate": 2.5538103548574757e-06,
      "loss": 1.3525,
      "step": 6000
    },
    {
      "epoch": 2.84,
      "learning_rate": 1.099476439790576e-06,
      "loss": 1.3753,
      "step": 6500
    }
  ],
  "logging_steps": 500,
  "max_steps": 6876,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 2369504579420160.0,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
